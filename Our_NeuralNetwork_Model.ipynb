{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kztaocR1vI90",
        "outputId": "3decded8-4d3c-47f2-a0e4-fa061c54e12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "left_dir = '/content/drive/MyDrive/CS543/project/left'\n",
        "right_dir = '/content/drive/MyDrive/CS543/project/right'\n",
        "not_active_dir = '/content/drive/MyDrive/CS543/project/not_active'\n",
        "\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = 128, 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/CS543/project',\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/CS543/project',\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    epochs=4\n",
        ")\n",
        "\n",
        "\n",
        "model.save('/content/drive/MyDrive/CS543/project/image_classifier_new.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRfkE6sevVrK",
        "outputId": "f064edaf-2a4f-4f44-b795-aea516159a4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8985 images belonging to 3 classes.\n",
            "Found 2245 images belonging to 3 classes.\n",
            "Epoch 1/4\n",
            "280/280 [==============================] - 239s 849ms/step - loss: 0.4208 - accuracy: 0.7985 - val_loss: 0.1834 - val_accuracy: 0.9496\n",
            "Epoch 2/4\n",
            "280/280 [==============================] - 169s 602ms/step - loss: 0.0388 - accuracy: 0.9894 - val_loss: 0.7792 - val_accuracy: 0.8589\n",
            "Epoch 3/4\n",
            "280/280 [==============================] - 168s 601ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.1654 - val_accuracy: 0.9500\n",
            "Epoch 4/4\n",
            "280/280 [==============================] - 167s 597ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.3638 - val_accuracy: 0.9277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "od4YZ8c845va"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}